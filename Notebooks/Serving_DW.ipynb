{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2bb7f6-5e71-4b99-86cc-d3a251d55f15",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# 1. CONFIGURATION SYNAPSE \n",
    "# ==============================================================================\n",
    "synapse_server = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "synapse_user = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "synapse_pass = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  \n",
    "synapse_db = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"             \n",
    "\n",
    "# Storage Info\n",
    "storage_account = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "container_name = \"curated\"\n",
    "\n",
    "# JDBC URL\n",
    "jdbc_url = f\"jdbc:sqlserver://{synapse_server}:1433;database={synapse_db};user={synapse_user};password={synapse_pass};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "\n",
    "# Dossier Temporaire\n",
    "temp_dir = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/synapse_staging_temp\"\n",
    "\n",
    "# COMMAND ----------\n",
    "# 2. AUTHENTICATION\n",
    "# ==============================================================================\n",
    "STORAGE_KEY = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n",
    "    STORAGE_KEY\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "# 3. LECTURE DEPUIS GOLD\n",
    "# ==============================================================================\n",
    "gold_path = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold_pollution_complete\"\n",
    "\n",
    "print(f\"üìÇ Lecture depuis : {gold_path}\")\n",
    "df_gold = spark.read.format(\"delta\").load(gold_path)\n",
    "\n",
    "# COMMAND ----------\n",
    "# 4. ECRITURE VERS SYNAPSE\n",
    "# ==============================================================================\n",
    "table_name = \"dbo.AirQuality_Predictions\"\n",
    "\n",
    "print(f\"üöÄ Envoi vers Synapse Table : {table_name}...\")\n",
    "\n",
    "try:\n",
    "    df_gold.write \\\n",
    "      .format(\"com.databricks.spark.sqldw\") \\\n",
    "      .option(\"url\", jdbc_url) \\\n",
    "      .option(\"forwardSparkAzureStorageCredentials\", \"true\") \\\n",
    "      .option(\"dbTable\", table_name) \\\n",
    "      .option(\"tempDir\", temp_dir) \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .save()\n",
    "      \n",
    "    print(\"‚úÖ Data est dans la DB.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur Synapse : {e}\")\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Serving_DW",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
